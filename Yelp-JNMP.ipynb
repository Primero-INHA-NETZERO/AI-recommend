{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7ce1b7c9-69a0-460b-9ced-6dcfa34b80cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kaggle.json\n"
     ]
    }
   ],
   "source": [
    "!mkdir -p ~/.kaggle\n",
    "!cp kaggle.json ~/.kaggle/\n",
    "!chmod 600 ~/.kaggle/kaggle.json\n",
    "!ls -1ha kaggle.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f5df1fda-ea33-49ed-a49d-33891dbe3480",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset URL: https://www.kaggle.com/datasets/yelp-dataset/yelp-dataset\n",
      "License(s): other\n",
      "Downloading yelp-dataset.zip to /shared/home/lexxsh\n",
      "100%|█████████████████████████████████████▉| 4.07G/4.07G [03:25<00:00, 21.9MB/s]\n",
      "100%|██████████████████████████████████████| 4.07G/4.07G [03:25<00:00, 21.3MB/s]\n"
     ]
    }
   ],
   "source": [
    "!kaggle datasets download -d yelp-dataset/yelp-dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "457e342d-b152-46e3-b468-2918b546cad0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archive:  yelp-dataset.zip\n",
      "  inflating: Dataset_User_Agreement.pdf  \n",
      "  inflating: yelp_academic_dataset_business.json  \n",
      "  inflating: yelp_academic_dataset_checkin.json  \n",
      "  inflating: yelp_academic_dataset_review.json  \n",
      "  inflating: yelp_academic_dataset_tip.json  \n",
      "  inflating: yelp_academic_dataset_user.json  \n"
     ]
    }
   ],
   "source": [
    "!unzip yelp-dataset.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b7f961b-8a28-4324-94a1-e086945cd909",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n",
      "Preprocessing data...\n",
      "Merging data...\n",
      "Creating user-item matrix...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2249610/3120160470.py:34: PerformanceWarning: The following operation may generate 75578691712 cells in the resulting pandas object.\n",
      "  user_item_matrix = merged_data.pivot_table(index='user_id', columns='business_id', values='stars').fillna(0)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from math import sqrt\n",
    "from scipy.sparse.linalg import svds\n",
    "from tqdm import tqdm\n",
    "\n",
    "# 데이터 로드\n",
    "print(\"Loading data...\")\n",
    "business_data = pd.read_json('yelp_academic_dataset_business.json', lines=True)\n",
    "review_data = pd.read_json('yelp_academic_dataset_review.json', lines=True)\n",
    "user_data = pd.read_json('yelp_academic_dataset_user.json', lines=True)\n",
    "\n",
    "# 데이터 전처리\n",
    "print(\"Preprocessing data...\")\n",
    "# 비즈니스 데이터에서 레스토랑 카테고리 필터링\n",
    "business_data = business_data[business_data['categories'].str.contains('Restaurants', na=False)]\n",
    "business_data = business_data[['business_id', 'name', 'categories']]\n",
    "\n",
    "# 리뷰 데이터에서 필요한 열 선택\n",
    "review_data = review_data[['user_id', 'business_id', 'stars']]\n",
    "\n",
    "# 사용자 데이터에서 필요한 열 선택\n",
    "user_data = user_data[['user_id', 'name']]\n",
    "\n",
    "# 데이터 병합\n",
    "print(\"Merging data...\")\n",
    "merged_data = pd.merge(review_data, business_data, on='business_id')\n",
    "merged_data = pd.merge(merged_data, user_data, on='user_id')\n",
    "\n",
    "# 사용자-가게-평점 행렬 생성\n",
    "print(\"Creating user-item matrix...\")\n",
    "user_item_matrix = merged_data.pivot_table(index='user_id', columns='business_id', values='stars').fillna(0)\n",
    "\n",
    "# Train/Test 분할\n",
    "print(\"Splitting data...\")\n",
    "train_data, test_data = train_test_split(user_item_matrix, test_size=0.2, random_state=0)\n",
    "\n",
    "# 사용자-가게 행렬에서 사용자, 아이템 행렬 추출 및 다루기\n",
    "print(\"Decomposing matrix...\")\n",
    "R = train_data.values\n",
    "user_ratings_mean = np.mean(R, axis = 1)\n",
    "R_demeaned = R - user_ratings_mean.reshape(-1, 1)\n",
    "\n",
    "# 행렬 분해 (Singular Value Decomposition)\n",
    "U, sigma, Vt = svds(R_demeaned, k=50)\n",
    "\n",
    "# 행렬 복원\n",
    "sigma = np.diag(sigma)\n",
    "all_user_predicted_ratings = np.dot(np.dot(U, sigma), Vt) + user_ratings_mean.reshape(-1, 1)\n",
    "predicted_ratings = pd.DataFrame(all_user_predicted_ratings, columns = train_data.columns)\n",
    "\n",
    "# 추천 함수\n",
    "def recommend_restaurants(predictions, user_id, num_recommendations=5):\n",
    "    user_idx = user_item_matrix.index.get_loc(user_id)\n",
    "    user_ratings = user_item_matrix.iloc[user_idx]\n",
    "    pred_ratings = predictions.iloc[user_idx]\n",
    "    sortable_recommendations = pred_ratings.where(user_ratings == 0).dropna(ascending=False).head(num_recommendations)\n",
    "    recommendations = list(sortable_recommendations.index)\n",
    "    return recommendations\n",
    "\n",
    "# RMSE 계산 함수\n",
    "def rmse(prediction, ground_truth):\n",
    "    prediction = prediction[ground_truth.nonzero()].flatten()\n",
    "    ground_truth = ground_truth[ground_truth.nonzero()].flatten()\n",
    "    return sqrt(mean_squared_error(prediction, ground_truth))\n",
    "\n",
    "# Cross-validation\n",
    "print(\"Performing cross-validation...\")\n",
    "n_folds = 5\n",
    "kf = KFold(n_splits=n_folds)\n",
    "rmse_scores = []\n",
    "for train_index, test_index in tqdm(kf.split(user_item_matrix.values), total=n_folds, desc='KFold Progress'):\n",
    "    train_data_cv, test_data_cv = user_item_matrix.values[train_index], user_item_matrix.values[test_index]\n",
    "    \n",
    "    # Train 데이터 처리\n",
    "    user_ratings_mean_cv = np.mean(train_data_cv, axis = 1)\n",
    "    R_demeaned_cv = train_data_cv - user_ratings_mean_cv.reshape(-1, 1)\n",
    "    \n",
    "    # 행렬 분해\n",
    "    U_cv, sigma_cv, Vt_cv = svds(R_demeaned_cv, k=50)\n",
    "    sigma_cv = np.diag(sigma_cv)\n",
    "    all_user_predicted_ratings_cv = np.dot(np.dot(U_cv, sigma_cv), Vt_cv) + user_ratings_mean_cv.reshape(-1, 1)\n",
    "    \n",
    "    # RMSE 계산\n",
    "    rmse_score = rmse(all_user_predicted_ratings_cv, test_data_cv)\n",
    "    rmse_scores.append(rmse_score)\n",
    "\n",
    "average_rmse = np.mean(rmse_scores)\n",
    "print(f\"Average RMSE across {n_folds}-folds: {average_rmse}\")\n",
    "\n",
    "# 예시 사용자에 대한 추천 생성\n",
    "example_user_id = user_item_matrix.index[0]\n",
    "recommended_restaurants = recommend_restaurants(predicted_ratings, example_user_id)\n",
    "print(f\"Recommended Restaurants for User {example_user_id}: {recommended_restaurants}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lexxs",
   "language": "python",
   "name": "lex"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
